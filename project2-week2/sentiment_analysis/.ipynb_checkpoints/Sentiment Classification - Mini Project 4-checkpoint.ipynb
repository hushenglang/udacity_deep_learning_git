{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification & How To \"Frame Problems\" for a Neural Network\n",
    "\n",
    "by Andrew Trask\n",
    "\n",
    "- **Twitter**: @iamtrask\n",
    "- **Blog**: http://iamtrask.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What You Should Already Know\n",
    "\n",
    "- neural networks, forward and back-propagation\n",
    "- stochastic gradient descent\n",
    "- mean squared error\n",
    "- and train/test splits\n",
    "\n",
    "### Where to Get Help if You Need it\n",
    "- Re-watch previous Udacity Lectures\n",
    "- Leverage the recommended Course Reading Material - [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) (40% Off: **traskud17**)\n",
    "- Shoot me a tweet @iamtrask\n",
    "\n",
    "\n",
    "### Tutorial Outline:\n",
    "\n",
    "- Intro: The Importance of \"Framing a Problem\"\n",
    "\n",
    "\n",
    "- Curate a Dataset\n",
    "- Developing a \"Predictive Theory\"\n",
    "- **PROJECT 1**: Quick Theory Validation\n",
    "\n",
    "\n",
    "- Transforming Text to Numbers\n",
    "- **PROJECT 2**: Creating the Input/Output Data\n",
    "\n",
    "\n",
    "- Putting it all together in a Neural Network\n",
    "- **PROJECT 3**: Building our Neural Network\n",
    "\n",
    "\n",
    "- Understanding Neural Noise\n",
    "- **PROJECT 4**: Making Learning Faster by Reducing Noise\n",
    "\n",
    "\n",
    "- Analyzing Inefficiencies in our Network\n",
    "- **PROJECT 5**: Making our Network Train and Run Faster\n",
    "\n",
    "\n",
    "- Further Noise Reduction\n",
    "- **PROJECT 6**: Reducing Noise by Strategically Reducing the Vocabulary\n",
    "\n",
    "\n",
    "- Analysis: What's going on in the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "56bb3cba-260c-4ebe-9ed6-b995b4c72aa3"
    }
   },
   "source": [
    "# Lesson: Curate a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "eba2b193-0419-431e-8db9-60f34dd3fe83"
    }
   },
   "outputs": [],
   "source": [
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
    "\n",
    "g = open('reviews.txt','r') # What we know!\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r') # What we WANT to know!\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "bb95574b-21a0-4213-ae50-34363cf4f87f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e0408810-c424-4ed4-afb9-1735e9ddbd0a"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Develop a Predictive Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e67a709f-234f-4493-bae6-4fb192141ee0"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.txt \t : \t reviews.txt\n",
      "\n",
      "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
      "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n",
      "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n",
      "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n",
      "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n",
      "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"
     ]
    }
   ],
   "source": [
    "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
    "pretty_print_review_and_label(2137)\n",
    "pretty_print_review_and_label(12816)\n",
    "pretty_print_review_and_label(6267)\n",
    "pretty_print_review_and_label(21934)\n",
    "pretty_print_review_and_label(5297)\n",
    "pretty_print_review_and_label(4998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Quick Theory Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bef29ecd7ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 'POSITIVE'):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "for word,ratio in pos_neg_ratios.most_common():\n",
    "    if(ratio > 1):\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = -np.log((1 / (ratio+0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# words most frequently seen in a review with a \"POSITIVE\" label\n",
    "pos_neg_ratios.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# words most frequently seen in a review with a \"NEGATIVE\" label\n",
    "list(reversed(pos_neg_ratios.most_common()))[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Text into Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "review = \"This was a horrible, terrible movie.\"\n",
    "\n",
    "Image(filename='sentiment_network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review = \"The movie was excellent\"\n",
    "\n",
    "Image(filename='sentiment_network_pos.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project 2: Creating the Input/Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = set(total_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "layer_0 = np.zeros((1,vocab_size))\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='sentiment_network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_input_layer(review):\n",
    "    \n",
    "    global layer_0\n",
    "    \n",
    "    # clear out previous state, reset the layer to be all 0s\n",
    "    layer_0 *= 0\n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "\n",
    "update_input_layer(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_for_label(label):\n",
    "    if(label == 'POSITIVE'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_target_for_label(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_target_for_label(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Building a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Start with your neural network from the last chapter\n",
    "- 3 layer neural network\n",
    "- no non-linearity in hidden layer\n",
    "- use our functions to create the training data\n",
    "- create a \"pre_process_data\" function to create vocabulary for our training data generating functions\n",
    "- modify \"train\" to train over the entire corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to Get Help if You Need it\n",
    "- Re-watch previous week's Udacity Lectures\n",
    "- Chapters 3-5 - [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) - (40% Off: **traskud17**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        # set our random number generator \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # TODO: Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # TODO: Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # TODO: Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluate our model before training (just to show how horrible it is)\n",
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the network\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the network\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the network\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Neural Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='sentiment_network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_input_layer(review):\n",
    "    \n",
    "    global layer_0\n",
    "    \n",
    "    # clear out previous state, reset the layer to be all 0s\n",
    "    layer_0 *= 0\n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "\n",
    "update_input_layer(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in reviews[0].split(\" \"):\n",
    "    review_counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_counter.most_common()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (root)",
   "language": "python",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
